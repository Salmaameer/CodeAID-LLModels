{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Libraries Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Imports and Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unsloth\n",
    "import torch\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "login(\"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\")\n",
    "\n",
    "base_model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "finetuned_model_id1 = \"CodeAid/solidV-Detection-model\"\n",
    "finetuned_model_id2 = \"CodeAid/couplingSmells-detection-model\"\n",
    "finetuned_model_SRefactor = \"CodeAid/SolidV-refactoring-model\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pydantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Principle = Literal[\n",
    "    \"Single Responsibility\", \"Open-Close\", \"Liskov\",\n",
    "    \"Interface Segregation\", \"Dependency Inversion\"\n",
    "]\n",
    "\n",
    "\n",
    "class ViolatedPrinciple(BaseModel):\n",
    "    principle: Principle = Field(..., description=\"The violated SOLID principle.\")\n",
    "    justification: str = Field(..., max_length=300,\n",
    "                               description=\"Explanation of why the principle was violated in 2 sentences only.\")\n",
    "\n",
    "\n",
    "class Violation(BaseModel):\n",
    "    main_file_path: str = Field(..., description=\"Path of the main file.\")\n",
    "    violatedPrinciples: List[ViolatedPrinciple] = Field(...,\n",
    "                                                        description=\"List of violated principles with justifications.\")\n",
    "\n",
    "\n",
    "class SolidDetectionOutput(BaseModel):\n",
    "    violations: Violation = Field(..., description=\"Detected SOLID violations.\")\n",
    "\n",
    "\n",
    "Smell = Literal[\n",
    "    \"Feature Envy\", \"Inappropriate Intimacy\",\n",
    "    \"Message Chains\", \"Middle Man\"\n",
    "]\n",
    "\n",
    "\n",
    "class CouplingSmell(BaseModel):\n",
    "    smell: Smell = Field(..., description=\"Type of coupling smell detected.\")\n",
    "    justification: str = Field(..., max_length=300,\n",
    "                               description=\"Justification for the detected coupling smell in 2 sentences only.\")\n",
    "\n",
    "\n",
    "class CouplingViolation(BaseModel):\n",
    "    filesPaths: List[str] = Field(..., description=\"Files involved in the coupling smell must include the main file.\")\n",
    "    smells: List[CouplingSmell] = Field(..., description=\"Details about the detected coupling smells.\")\n",
    "\n",
    "\n",
    "class CouplingDetectionOutput(BaseModel):\n",
    "    couplingSmells: List[CouplingViolation] = Field(..., description=\"Detected coupling code smells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Solid Refactoring pydantics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefactoredFile(BaseModel):\n",
    "    filePath: str = Field(..., description=\"Path to the file either created or refactored.\")\n",
    "    fileContent: str = Field(..., description=\"The full content of the file\")\n",
    "\n",
    "class RefactoringOutput(BaseModel):\n",
    "    refactored_files: List[RefactoredFile] = Field(..., description=\"List of all refactored files and their changes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only choose one cell to execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.5: Fast Qwen2 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 21.964 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481a7de00cfb47e7a4089668f80db1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00818bbf89a4c65813cd76ed42a57d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f157c655954069811bfd9479138827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742eea2b1bb4464d8e93bb149366b006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f1c7bc4ab94abd953be12c2191c73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c309ea3c394b47cd9d13c2bd1f2612dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828ea3b2f7fb424495dd1b2f09daab3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9dc12717bb4d2397910e5e421ef0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = base_model_id,\n",
    "    max_seq_length=32768,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SOLID Violations Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = finetuned_model_id1,\n",
    "    max_seq_length=32768,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Coupling Smells Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = finetuned_model_id2,\n",
    "    max_seq_length=32768,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Solid Violations Refactoring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = finetuned_model_SRefactor,\n",
    "    max_seq_length=32768,\n",
    "    dtype = torch.float16,\n",
    "    load_in_4bit = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Prompt Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prompt(prompt_text: str):\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=8192)\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    return decoded_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_solid_violations(input_path, output_path1):\n",
    "    with open(input_path, \"r\") as f_in, open(output_path1, \"a\") as f_out1:\n",
    "        for line in f_in:\n",
    "            data = json.loads(line)\n",
    "\n",
    "            solid_violations_detection_messages =  \"\\n\".join([\n",
    "                \"You are a senior software engineer.\",\n",
    "                \"You will be given one Java file (main file) along with its file dependencies.\",\n",
    "                \"Your task is to detect violations of SOLID principles *only in the main_file_content*: Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, and Dependency Inversion.\",\n",
    "                \"\",\n",
    "                \"You can use the dependency files just for context, but only analyze and extract violations from the main_file_content only.\",\n",
    "                \"\",\n",
    "                \"Principle definitions (apply these strictly):\",\n",
    "                \"SRP: A class has exactly one reason to changeâ€”only one responsibility.\",\n",
    "                \"OCP: A class may be extended without modifying its existing code.\",\n",
    "                \"LSP: Subtypes must behave interchangeably with their base types.\",\n",
    "                \"ISP: Clients should only depend on the methods they actually use.\",\n",
    "                \"DIP: Highâ€‘level (policy/business) modules must depend on abstractions (interfaces/abstract classes), not on concrete (implementation) classes. Lowâ€‘level modules must implement those abstractions; they should NOT be directly referenced by highâ€‘level modules.\",\n",
    "                \"Don't include the usage of built-in classes (e.g. java.util.Scanner, java.lang.String, List, Map), they don't break DIP.\",\n",
    "                \"\",\n",
    "                \"Apply a step-by-step reasoning process to identify any violations.\",\n",
    "                \"Start by explaining what each principle means in the current context, and how the main file code complies or fails to comply with it.\",\n",
    "                \"\",\n",
    "                \"After providing your first assessment, re-evaluate your findings and refine your judgment if necessary.\",\n",
    "                \"\",\n",
    "                \"Finally, reflect on your answer: did you miss anything? Could your answer be improved? If so, revise accordingly.\",\n",
    "                \"\",\n",
    "                \"Always respond in a structured JSON format. Do not include any explanation outside the JSON.\",\n",
    "                \"You have to extract SOLID Violations from the *main file code only* according to the following Pydantic schema.\",\n",
    "                \"Be objective and thorough, even if no violations are found.\",\n",
    "                \"Do not generate any introduction or conclusion.\",\n",
    "                \"\",\n",
    "                \"## Code:\",\n",
    "                json.dumps(data[\"content\"], ensure_ascii=False),\n",
    "                \"\",\n",
    "                \"## Pydantic Details:\",\n",
    "                json.dumps(SolidDetectionOutput.model_json_schema(), ensure_ascii=False),\n",
    "                \"\",\n",
    "                \"## SOLID Violations:\",\n",
    "                \"json\"\n",
    "            ])\n",
    "\n",
    "            response1 = send_prompt(solid_violations_detection_messages)\n",
    "\n",
    "\n",
    "            result1 = {\n",
    "                \"output\": response1\n",
    "            }\n",
    "           \n",
    "            f_out1.write(json.dumps(result1) + \"\\n\")\n",
    "            print(\"done\")\n",
    "\n",
    "def detect_coupling(input_path, output_path1):\n",
    "    with open(input_path, \"r\") as f_in, open(output_path1, \"a\") as f_out1:\n",
    "        for line in f_in:\n",
    "            data = json.loads(line)\n",
    "            coupling_smells_detection_messages = \"\\n\".join([\n",
    "                \"You are a software engineer.\",\n",
    "                \"You will be given one file with its file dependencies. Just extract coupling smells that is related to main_file_content\",\n",
    "                \"Your task is to identify and explain any of the following coupling smells:\",\n",
    "                \"\",\n",
    "                \"- Feature Envy: A method that seems more interested in another class than the one it is in, accessing its data and methods frequently.\",\n",
    "                \"- Inappropriate Intimacy: Two classes that share too much information or access each other's internal details excessively.\",\n",
    "                \"- Incomplete Library Class: A library class is missing functionality that should be there, forcing users to add methods or subclasses that break encapsulation.\",\n",
    "                \"- Message Chains: A client asks one object for another object, then that object for another, and so on, forming a long chain of calls.\",\n",
    "                \"- Middle Man: A class that delegates almost everything to another class and does very little itself.\",\n",
    "                \"\",\n",
    "                \"Use a step-by-step reasoning process (Chain of Thought) to evaluate if any of these smells exist in the code.\",\n",
    "                \"For each suspected smell, explain what triggered it, and which class/method is involved.\",\n",
    "                \"\",\n",
    "                \"After your first pass, review your analysis and refine it if necessary.\",\n",
    "                \"Then, critically evaluate your final result.\",\n",
    "                \"- Did you miss any smell?\",\n",
    "                \"- Did you misclassify anything?\",\n",
    "                \"- Could your reasoning be more precise?\",\n",
    "                \"\",\n",
    "                \"Always respond in a structured JSON format. Do not include any explanation outside the JSON.\",\n",
    "                \"You have to extract Coupling code smells from Code according the Pydantic details.\",\n",
    "                \"Be objective and thorough, even if no violations are found.\",\n",
    "                \"Do not generate any introduction or conclusion.\",\n",
    "                \"## Code:\",\n",
    "                json.dumps(data[\"content\"], ensure_ascii=False),\n",
    "                \"\",\n",
    "                \"## Pydantic Details:\",\n",
    "                json.dumps(CouplingDetectionOutput.model_json_schema(), ensure_ascii=False),\n",
    "                \"\",\n",
    "                \"## Coupling code smells:\",\n",
    "                \"json\"\n",
    "            ])\n",
    "            response1 = send_prompt(coupling_smells_detection_messages)\n",
    "\n",
    "\n",
    "            result1 = {\n",
    "                \"output\": response1\n",
    "            }\n",
    "            \n",
    "            f_out1.write(json.dumps(result1) + \"\\n\")\n",
    "            print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_solid_violations(input_path, output_path):\n",
    "    with open(input_path, \"r\") as f_in, open(output_path, \"a\") as f_out:\n",
    "        for line in f_in:\n",
    "            data = json.loads(line)\n",
    "\n",
    "            solid_violations_refactoring_messages =  \"\\n\".join([\n",
    "                        \"You are an expert Java developer specialized in applying Single Responsibility and Open-Closed principles through code refactoring.\",\n",
    "                        \"You will be given one main Java file, with some dependencies (maybe none) along with a structured JSON detailing the detected Single Responsibility, Open-Closed violations in the main file.\",\n",
    "                        \"Your task is to refactor the code to eliminate these violations while maintaining and improving overall code clarity and design.\",\n",
    "                        \"\",\n",
    "                        \"For reference, here are brief descriptions of the SRP and OCP principles:\",\n",
    "                        \"- SRP (Single Responsibility): A class should have only one reason to change, i.e., one responsibility.\",\n",
    "                        \"- OCP (Open/Closed): Classes should be open for extension, but closed for modification.\",\n",
    "                        \"Apply a step-by-step reasoning process to identify the best approach for refactoring each violation.\",\n",
    "                        \"After making initial changes, re-evaluate the result and improve it further if needed.\",\n",
    "                        \"Then, reflect on the outcome: did you miss anything? Did your refactoring introduce new issues? If so, revise accordingly.\",\n",
    "                        \"You should return the main file in case of being updated with its updated content.\",\n",
    "                        \"You should return the created files with its content.\",\n",
    "                        \"Never add multiple classes/enums/interfaces in the same file; if needed, create a new file for each.\",\n",
    "                        \"After refactoring the main file and adding any new files, you must:\",\n",
    "                        \"- Review all dependency files for references to the main fileâ€™s class, methods, or fields.\",\n",
    "                        \"- Update those dependency files to reflect any renames, deletions, or new methods introduced in your refactor.\",\n",
    "                        \"- Ensure there are no invalid references in dependency files (such as calling a method that no longer exists).\",\n",
    "                        \"All updated dependency files should be included in your output alongside the main file and new files, following the Pydantic schema format.\",\n",
    "                        \"Don't return a file unless it is updated or created.\",\n",
    "                        \"\",\n",
    "                        \"## Critical Output and Formatting Rules:\",\n",
    "                        \"1. **Comment Formatting for Unfixable Dependencies:** This is a strict requirement. If a dependency cannot be updated due to missing context, you must leave a comment. IT IS CRITICAL that you add a line break (`\\\\n`) immediately after the comment. The code that follows the comment MUST start on a new line to avoid compilation errors.\",\n",
    "                        \"2. **No Extra Content:** Do not include any explanation, introduction, or conclusion outside the final JSON output.\",\n",
    "                        \"3. **Code Formatting:** Return the code in one line without extra spaces or break lines. Don't add any comments.\",\n",
    "                        \"4. **JSON Structure:** You must follow the format defined in the Pydantic schema for the refactoring output.\",\n",
    "                        \"\",\n",
    "                        \"Be precise, complete, and objective. If no changes are needed, reflect that in the response.\",\n",
    "                        \"## Code:\",\n",
    "                        json.dumps(data[\"prompt\"], ensure_ascii=False),\n",
    "                        \"\",\n",
    "                        \"## SO Violations:\",\n",
    "                        json.dumps(data[\"violations\"], ensure_ascii=False),\n",
    "                        \"\",\n",
    "                        \"## Pydantic Details:\",\n",
    "                        json.dumps(RefactoringOutput.model_json_schema(), ensure_ascii=False),\n",
    "                        \"\",\n",
    "                        \"## Refactored Code:\",\n",
    "                        \"```json\"\n",
    "                    ])\n",
    "\n",
    "            response = send_prompt(solid_violations_refactoring_messages)           \n",
    "\n",
    "            result = {\n",
    "                \"output\": response\n",
    "            }\n",
    "           \n",
    "            f_out.write(json.dumps(result) + \"\\n\")\n",
    "            print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution For Testing Before & After Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_solid_violations(\"data.jsonl\", \"outputFile1.jsonl\")\n",
    "detect_coupling(\"data.jsonl\", \"outputFile2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refactor_solid_violations(\"test.jsonl\",\"outRefactor.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
